# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
import json
import multiprocessing as mp
import pickle
import os
import torch

from utils import iou_with_anchors


def load_json(file):
    with open(file) as json_file:
        data = json.load(json_file)
        return data


def load_pickle(path):
    with open(path, 'rb') as f:
        data = pickle.load(f)
    return data


def getDatasetDict(opt):
    subset_map = {"train": "training",
                  "validation": "validation",
                  "test": "testing"}
    subset = subset_map[opt['inference_dataset']]
    target_fps = opt["frames_fps"]
    json_data = load_json(opt["video_anno"])
    anno_database = json_data['database']
    video_dict = {}
    for video_name, anno in anno_database.items():
        video_subset = anno['subset']
        if video_subset != subset:
            continue
        video_new_info = {}
        video_new_info['duration_second'] = float(anno["duration"])
        video_new_info['annotations'] = anno['annotations']
        video_dict[video_name] = video_new_info
    return video_dict


def soft_nms(df, alpha, t1, t2):
    '''
    df: proposals generated by network;
    alpha: alpha value of Gaussian decaying function;
    t1, t2: threshold for soft nms.
    '''
    df = df.sort_values(by="score", ascending=False)
    tstart = list(df.xmin.values[:])
    tend = list(df.xmax.values[:])
    tscore = list(df.score.values[:])

    rstart = []
    rend = []
    rscore = []

    while len(tscore) > 1 and len(rscore) < 101:
        max_index = tscore.index(max(tscore))
        tmp_iou_list = iou_with_anchors(
            np.array(tstart),
            np.array(tend), tstart[max_index], tend[max_index])
        for idx in range(0, len(tscore)):
            if idx != max_index:
                tmp_iou = tmp_iou_list[idx]
                tmp_width = (tend[max_index] - tstart[max_index])
                if tmp_iou > t1 + (t2 - t1) * tmp_width:
                    tscore[idx] = tscore[idx] * np.exp(-np.power(tmp_iou, 2.5) /
                                                       alpha)

        rstart.append(tstart[max_index])
        rend.append(tend[max_index])
        rscore.append(tscore[max_index])
        tstart.pop(max_index)
        tend.pop(max_index)
        tscore.pop(max_index)

    newDf = pd.DataFrame()
    newDf['score'] = rscore
    newDf['xmin'] = rstart
    newDf['xmax'] = rend
    return newDf


def video_post_process(opt, video_list, video_dict, prefix="BMN"):
    for video_name in video_list:
        video_info = video_dict[video_name]
        video_duration = video_info["duration_second"]

        df = pd.read_csv(os.path.join(opt["checkpoint_path"],
                                      "{}_results".format(prefix), video_name + ".csv"))
        df['score'] = df.ori_score.values[:] * df.preds_iou3.values[:]  # * np.power(df.c_score.values[:], 0.1)

        if len(df) > 1:
            snms_alpha = opt["soft_nms_alpha"]
            snms_t1 = opt["soft_nms_low_thres"]
            snms_t2 = opt["soft_nms_high_thres"]
            df = soft_nms(df, snms_alpha, snms_t1, snms_t2)

        df = df.sort_values(by="score", ascending=False)
        proposal_list = []

        for j in range(min(100, len(df))):
            tmp_proposal = {}
            tmp_proposal["score"] = df.score.values[j]
            tmp_proposal["segment"] = [max(0, df.xmin.values[j]) * video_duration,
                                       min(1, df.xmax.values[j]) * video_duration]
            proposal_list.append(tmp_proposal)
        result_dict[video_name] = proposal_list


def TCA_post_processing(opt):
    BMN_post_processing(opt, "TCA")


def BMN_post_processing(opt, prefix="BMN"):
    video_dict = getDatasetDict(opt)
    video_list = list(video_dict.keys())  # [:100]
    global result_dict
    result_dict = mp.Manager().dict()
    num_videos = len(video_list)

    # post_process = merge_post_process
    post_process = video_post_process
    # post_process(opt, video_list, video_dict)

    num_videos_per_thread = num_videos // opt["post_process_thread"]
    processes = []
    for tid in range(opt["post_process_thread"] - 1):
        tmp_video_list = video_list[tid * num_videos_per_thread:(tid + 1) * num_videos_per_thread]
        p = mp.Process(target=post_process, args=(opt, tmp_video_list, video_dict, prefix))
        p.start()
        processes.append(p)
    tmp_video_list = video_list[(opt["post_process_thread"] - 1) * num_videos_per_thread:]
    p = mp.Process(target=post_process, args=(opt, tmp_video_list, video_dict, prefix))
    p.start()
    processes.append(p)
    for p in processes:
        p.join()

    result_dict = dict(result_dict)
    output_dict = {"results": result_dict}
    outfile = open(opt["proposals_result_file"], "w")
    json.dump(output_dict, outfile)
    outfile.close()
    if opt["output_detection_result"] != "False":
        save_detection_result(opt, result_dict)


def save_detection_result(opt, proposals_dict):
    print("processing detection results^^^^^")
    subset_map = {"train": "training",
                  "validation": "validation",
                  "test": "testing"}
    inference_dataset = subset_map[opt['inference_dataset']]
    classifier_data = load_json(opt["classifier_result"].format(inference_dataset))
    score = classifier_data["results"]
    action = classifier_data["class"]
    detection_result_dict = {}
    use_topk = 3
    topk_weight = [1.0, 1.0, 1.0, 1.0, 1.0]
    max_det_result = 200
    for video_name, proposal_list in proposals_dict.items():
        if video_name not in score:
            print("{} not found!".format(video_name))
            continue
        video_scores = score[video_name][0]
        video_scores = (torch.tensor(video_scores) * 2.0).softmax(dim=0).tolist()
        sort_idx = np.argsort(video_scores).tolist()[::-1]
        topk_result_list = []
        for i in range(use_topk):
            label = action[sort_idx[i]]
            one_score = video_scores[sort_idx[i]]
            for proposal in proposal_list:
                # if proposal["score"] < 0.01:
                #     continue
                det_score = one_score * proposal["score"] * topk_weight[i]
                topk_result_list.append([det_score, label, proposal["segment"]])
        topk_result_list.sort(key=lambda x: x[0], reverse=True)
        result_list = []
        for i in range(min(max_det_result, len(topk_result_list))):
            tmp_detection = {}
            tmp_detection["label"] = topk_result_list[i][1]
            tmp_detection["score"] = topk_result_list[i][0]
            tmp_detection["segment"] = topk_result_list[i][2]
            result_list += [tmp_detection]
        detection_result_dict[video_name] = result_list
        '''
        video_class = action[np.argmax(video_scores)]
        video_score = max(video_scores)
        result_list = []
        for proposal in proposal_list:
            tmp_detection = {}
            tmp_detection["label"] = video_class
            tmp_detection["score"] = video_score * proposal["score"]
            tmp_detection["segment"] = proposal["segment"]
            result_list += [tmp_detection]
        detection_result_dict[video_name] = result_list
        '''
    output_dict = {"results": detection_result_dict}
    with open(opt["detection_result_file"], "w") as f:
        json.dump(output_dict, f)
    print("processing detection results saved!")

